{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4345576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D,BatchNormalization,UpSampling1D,Conv1DTranspose,Dense,Flatten,Reshape,Attention, Add, Multiply, Activation,LeakyReLU\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from mat4py import loadmat\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "import scipy.io\n",
    "from biosppy.signals import ecg\n",
    "from scipy import signal\n",
    "from math import log10, sqrt\n",
    "from keras.layers import LSTM\n",
    "from keras import backend as K\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import LSTM, Input, Dropout\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets\n",
    "from ecgdetectors import Detectors\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import butter, filtfilt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9614c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ecg(ecg_signal):\n",
    "    \"\"\"\n",
    "    Normalize the ECG signal using min-max normalization\n",
    "    \"\"\"\n",
    "    # Find the minimum and maximum values of the signal\n",
    "    min_val = np.min(ecg_signal)\n",
    "    max_val = np.max(ecg_signal)\n",
    "\n",
    "    # Normalize the signal using min-max normalization\n",
    "    normalized_ecg = (ecg_signal - min_val) / (max_val - min_val)\n",
    "\n",
    "    return normalized_ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68304673",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('115m.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8a0ef0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(650000,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa=mat['val']\n",
    "a=aa[0,0:]\n",
    "a=normalize_ecg(a)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbc1e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original sampling rate and desired new sampling rate\n",
    "original_sampling_rate =360    # Replace with your actual sampling rate\n",
    "new_sampling_rate = 250  # Desired new sampling rate\n",
    "\n",
    "# Calculate the new length of the resampled signal\n",
    "original_length = len(a)\n",
    "new_length = int(original_length * (new_sampling_rate / original_sampling_rate))\n",
    "\n",
    "# Resample the signal\n",
    "r_ecg = signal.resample(a, new_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f207326",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ecg.christov_segmenter(signal=r_ecg, sampling_rate=250)\n",
    "rpeaks = out['rpeaks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "412f779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_length = 600  # Fixed segment length of 600 data points\n",
    "window_size_seconds = 2.4  # Time window of 2.4 seconds\n",
    "segments = []\n",
    "\n",
    "\n",
    "for i in range(0, len(rpeaks) - 3, 2):  # Step by 2 to get two R-peaks per segment\n",
    "    rpeak1 = rpeaks[i]\n",
    "    rpeak2 = rpeaks[i + 1]\n",
    "    \n",
    "    # Calculate the midpoint between the two R-peaks\n",
    "    midpoint = (rpeak1 + rpeak2) // 2\n",
    "    \n",
    "    # Calculate the segment start and end indices for the specified window size\n",
    "    window_size_samples = int(250 * window_size_seconds)\n",
    "    segment_start = max(0, midpoint - window_size_samples // 2)\n",
    "    segment_end = segment_start + segment_length\n",
    "    \n",
    "    # Check if segment_end goes beyond the signal length\n",
    "    if segment_end > len(r_ecg):\n",
    "        # Perform zero-padding if necessary\n",
    "        segment = np.pad(r_ecg[segment_start:], (0, segment_end - len(r_ecg)))\n",
    "    else:\n",
    "        segment = r_ecg[segment_start:segment_end]\n",
    "    \n",
    "    segments.append(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "808ae298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 600)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=np.array(segments)\n",
    "# data1=data.reshape((200,300))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b76b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train, Y_test = train_test_split(data, test_size=0.2)\n",
    "Y_test.shape\n",
    "y=len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "517fa16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06fc17d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 600, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 600, 16)      224         ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)     (None, 600, 16)      0           ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 300, 16)     0           ['leaky_re_lu_16[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 300, 32)      3616        ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)     (None, 300, 32)      0           ['conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPooling1D)  (None, 150, 32)     0           ['leaky_re_lu_17[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 150, 64)      14400       ['max_pooling1d_7[0][0]']        \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)     (None, 150, 64)      0           ['conv1d_16[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_8 (MaxPooling1D)  (None, 75, 64)      0           ['leaky_re_lu_18[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 75, 128)      57472       ['max_pooling1d_8[0][0]']        \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)     (None, 75, 128)      0           ['conv1d_17[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 9600)         0           ['leaky_re_lu_19[0][0]']         \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 1)            9601        ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 1)            9601        ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " sampling_2 (Sampling)          (None, 1)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 94,914\n",
      "Trainable params: 94,914\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 1\n",
    "encoder_inputs = keras.Input(shape=(600, 1))\n",
    "x=Conv1D(16,13,padding='same')(encoder_inputs)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "x=MaxPooling1D(2)(x)\n",
    "\n",
    "x=Conv1D(32,7,padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "x=MaxPooling1D(2)(x)\n",
    "\n",
    "x=Conv1D(64,7,padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "x=MaxPooling1D(2)(x)\n",
    "\n",
    "x=Conv1D(128,7,padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "conv_shape=K.int_shape(x)\n",
    "x=Flatten()(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5605038d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 9600)              19200     \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 75, 128)           0         \n",
      "                                                                 \n",
      " conv1d_transpose_8 (Conv1DT  (None, 75, 128)          114816    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 75, 128)           0         \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 75, 128)           49280     \n",
      "                                                                 \n",
      " conv1d_transpose_9 (Conv1DT  (None, 75, 64)           57408     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 75, 64)            0         \n",
      "                                                                 \n",
      " up_sampling1d_6 (UpSampling  (None, 150, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 150, 64)           12352     \n",
      "                                                                 \n",
      " conv1d_transpose_10 (Conv1D  (None, 150, 32)          14368     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 150, 32)           0         \n",
      "                                                                 \n",
      " up_sampling1d_7 (UpSampling  (None, 300, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_20 (Conv1D)          (None, 300, 32)           3104      \n",
      "                                                                 \n",
      " conv1d_transpose_11 (Conv1D  (None, 300, 16)          6672      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 300, 16)           0         \n",
      "                                                                 \n",
      " up_sampling1d_8 (UpSampling  (None, 600, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 9600)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 600)               5760600   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,037,800\n",
      "Trainable params: 6,037,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x=Dense(conv_shape[1]*conv_shape[2],activation='relu')(latent_inputs)\n",
    "x=Reshape((conv_shape[1],conv_shape[2]))(x)\n",
    "# decoder_inputs=encoder(inputs)[2]\n",
    "x=Conv1DTranspose(128,7,padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "x=Conv1D(128, kernel_size=3, padding='same')(x)\n",
    "\n",
    "x=Conv1DTranspose(64,7,padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "x=UpSampling1D(2)(x)\n",
    "\n",
    "x=Conv1D(64, kernel_size=3, padding='same')(x)\n",
    "\n",
    "x=Conv1DTranspose(32,7,padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "x=UpSampling1D(2)(x)\n",
    "\n",
    "x=Conv1D(32, kernel_size=3, padding='same')(x)\n",
    "\n",
    "x=Conv1DTranspose(16,13,padding='same')(x)\n",
    "x=LeakyReLU(alpha=0.2)(x)\n",
    "x=UpSampling1D(2)(x)\n",
    "x=Flatten()(x)\n",
    "decoder_outputs=Dense(600,activation='linear')(x)\n",
    "\n",
    "# decoder_outputs=Reshape((2000,1))(decoder_outputs)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a2db38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    tf.reduce_sum(keras.losses.mean_squared_error(data, reconstruction), axis=-1)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3b267cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 [==============================] - 11s 224ms/step - loss: 6.9278 - reconstruction_loss: 4.4056 - kl_loss: 0.0309\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 4s 200ms/step - loss: 0.3696 - reconstruction_loss: 0.2085 - kl_loss: 0.0097\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 5s 233ms/step - loss: 0.0449 - reconstruction_loss: 0.0388 - kl_loss: 4.4666e-04\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 7s 354ms/step - loss: 0.0241 - reconstruction_loss: 0.0237 - kl_loss: 2.8048e-05\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 7s 344ms/step - loss: 0.0233 - reconstruction_loss: 0.0223 - kl_loss: 5.9591e-06\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 7s 356ms/step - loss: 0.0134 - reconstruction_loss: 0.0219 - kl_loss: 8.0060e-07\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 7s 361ms/step - loss: 0.0142 - reconstruction_loss: 0.0222 - kl_loss: 3.0582e-07\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 7s 356ms/step - loss: 0.0220 - reconstruction_loss: 0.0222 - kl_loss: 3.6756e-07\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 7s 351ms/step - loss: 0.0207 - reconstruction_loss: 0.0225 - kl_loss: 2.9747e-07\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 7s 360ms/step - loss: 0.0213 - reconstruction_loss: 0.0221 - kl_loss: 3.0944e-07\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 7s 354ms/step - loss: 0.0200 - reconstruction_loss: 0.0226 - kl_loss: 3.0380e-07\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 7s 353ms/step - loss: 0.0270 - reconstruction_loss: 0.0225 - kl_loss: 3.1287e-07\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 7s 352ms/step - loss: 0.0156 - reconstruction_loss: 0.0221 - kl_loss: 3.0013e-07\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 7s 353ms/step - loss: 0.0363 - reconstruction_loss: 0.0220 - kl_loss: 3.0754e-07\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 7s 346ms/step - loss: 0.0217 - reconstruction_loss: 0.0220 - kl_loss: 2.9285e-07\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 7s 361ms/step - loss: 0.0220 - reconstruction_loss: 0.0223 - kl_loss: 2.8300e-07\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 7s 351ms/step - loss: 0.0205 - reconstruction_loss: 0.0231 - kl_loss: 2.8072e-07\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 7s 360ms/step - loss: 0.0235 - reconstruction_loss: 0.0244 - kl_loss: 3.1203e-07\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 7s 353ms/step - loss: 0.0152 - reconstruction_loss: 0.0225 - kl_loss: 2.8532e-07\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 7s 354ms/step - loss: 0.0223 - reconstruction_loss: 0.0224 - kl_loss: 3.2273e-07\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 7s 361ms/step - loss: 0.0226 - reconstruction_loss: 0.0232 - kl_loss: 2.7384e-07\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 7s 353ms/step - loss: 0.0204 - reconstruction_loss: 0.0223 - kl_loss: 2.7758e-07\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 7s 355ms/step - loss: 0.0157 - reconstruction_loss: 0.0221 - kl_loss: 2.5258e-07\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 7s 360ms/step - loss: 0.0266 - reconstruction_loss: 0.0222 - kl_loss: 2.8658e-07\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 7s 360ms/step - loss: 0.0182 - reconstruction_loss: 0.0227 - kl_loss: 4.8748e-07\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 7s 356ms/step - loss: 0.0155 - reconstruction_loss: 0.0225 - kl_loss: 3.3950e-07\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 7s 355ms/step - loss: 0.0263 - reconstruction_loss: 0.0233 - kl_loss: 2.5306e-07\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 7s 361ms/step - loss: 0.0246 - reconstruction_loss: 0.0233 - kl_loss: 2.3371e-07\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 7s 359ms/step - loss: 0.0178 - reconstruction_loss: 0.0225 - kl_loss: 2.1957e-07\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 7s 360ms/step - loss: 0.0227 - reconstruction_loss: 0.0223 - kl_loss: 3.1766e-07\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 7s 351ms/step - loss: 0.0167 - reconstruction_loss: 0.0237 - kl_loss: 2.4502e-07\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 7s 368ms/step - loss: 0.0330 - reconstruction_loss: 0.0229 - kl_loss: 2.1948e-07\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 7s 373ms/step - loss: 0.0195 - reconstruction_loss: 0.0235 - kl_loss: 1.9741e-07\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 7s 355ms/step - loss: 0.0226 - reconstruction_loss: 0.0223 - kl_loss: 2.7115e-07\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 7s 374ms/step - loss: 0.0193 - reconstruction_loss: 0.0224 - kl_loss: 1.9540e-07\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 7s 367ms/step - loss: 0.0337 - reconstruction_loss: 0.0228 - kl_loss: 1.9298e-07\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 7s 359ms/step - loss: 0.0316 - reconstruction_loss: 0.0239 - kl_loss: 1.7893e-07\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 7s 353ms/step - loss: 0.0235 - reconstruction_loss: 0.0233 - kl_loss: 2.0567e-07\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 7s 368ms/step - loss: 0.0161 - reconstruction_loss: 0.0232 - kl_loss: 2.2249e-07\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 7s 366ms/step - loss: 0.0330 - reconstruction_loss: 0.0233 - kl_loss: 3.4356e-07\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 7s 367ms/step - loss: 0.0239 - reconstruction_loss: 0.0235 - kl_loss: 3.8086e-07\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 7s 358ms/step - loss: 0.0231 - reconstruction_loss: 0.0223 - kl_loss: 2.4910e-07\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 7s 347ms/step - loss: 0.0155 - reconstruction_loss: 0.0235 - kl_loss: 2.7974e-07\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 7s 358ms/step - loss: 0.0179 - reconstruction_loss: 0.0229 - kl_loss: 2.7395e-07\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 7s 350ms/step - loss: 0.0185 - reconstruction_loss: 0.0226 - kl_loss: 1.6799e-07\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 7s 358ms/step - loss: 0.0291 - reconstruction_loss: 0.0232 - kl_loss: 2.0467e-07\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 7s 369ms/step - loss: 0.0228 - reconstruction_loss: 0.0236 - kl_loss: 1.7538e-07\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 7s 358ms/step - loss: 0.0431 - reconstruction_loss: 0.0232 - kl_loss: 2.6712e-07\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 7s 365ms/step - loss: 0.0156 - reconstruction_loss: 0.0228 - kl_loss: 2.1493e-07\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 7s 356ms/step - loss: 0.0205 - reconstruction_loss: 0.0235 - kl_loss: 1.6301e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d609797070>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE(encoder,decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(Y_train, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17276c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 600)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z, _, _ = vae.encoder.predict(Y_test)\n",
    "pred=vae.decoder.predict(z)\n",
    "# # pred=np.array(pred)\n",
    "#pred=vae.decoder.predict(vae.encoder.predict(X_test)[2])\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21a35b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRD: 3.3947677934920235\n",
      "SNR: 30.130893286153245\n"
     ]
    }
   ],
   "source": [
    "p1=0\n",
    "s1=0;\n",
    "for x in range(y):\n",
    "    rec1=pred[x]\n",
    "    xtrn1=Y_test[x]\n",
    "    actual= xtrn1\n",
    "    predicted= rec1\n",
    "    sme= np.sum(np.square(actual - predicted))\n",
    "    org = np.sum(np.square(actual))\n",
    "    prd1= np.sqrt(sme/org)*100\n",
    "    p1=p1+prd1;\n",
    "    signal_power = np.sum(actual ** 2) / len(actual)\n",
    "    noise_signal = actual-predicted\n",
    "    noise_power = np.sum(noise_signal ** 2) / len(noise_signal)\n",
    "    snr_db = 10 * np.log10(signal_power / noise_power)\n",
    "    s1=s1+snr_db;\n",
    "\n",
    "prd=p1/y;\n",
    "snr_d=s1/y;\n",
    "print(\"PRD:\",prd) \n",
    "print(\"SNR:\",snr_d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e6b929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9550ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05c438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177e296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3bce85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d365dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cfb400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e76611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ecc86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff43512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd14df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ba077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c89065e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2405a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bf9a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d378466c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
